## ref: https://confluence.app.alcatel-lucent.com/display/plateng/HELM+Application+Deployment+-+LIFECYCLE#HELMApplicationDeployment-LIFECYCLE-RelocatableChart
### global registry
global:
  # This registry is used for elasticsearch image
  registry: csf-docker-delivered.repo.lab.pl.alcatel-lucent.com
  # This registry is used for cbur and kubectl images
  registry1: csf-docker-delivered.repo.lab.pl.alcatel-lucent.com
  preheal: 0
  postheal: 0
  seccompAllowedProfileNames: docker/default
  seccompDefaultProfileName: docker/default

  #you can add prefixes to pod and container names by providing values for below parameters
  ##Provide lowercase alphanumeric characters, '-' or '.'
  #Consider suffixing the podNamePrefix and containerNamePrefix with either - for convenience
  podNamePrefix:
  containerNamePrefix:

  # Istio-related parameters
  istio:
    #Istio version defined at global level. Accepts version in numeric X.Y format. Ex. 1.4/1.5
    version: 1.4

  #If rbac.enabled is set to false, then it is mandatory to provide precreated Service account either at global level or at individual chart level.
  rbac:
    enabled: true
  #User can specify the precreated global SA here
  serviceAccountName: ""

#User can configure the precreated SA specifically for this chart here. SA specified here takes precedence over the SA specified in global.
#If precreated SA is not provided at global and individual chart level and rbac.enabled is set to true, then rbac objects will be created by the chart.
serviceAccountName: ""

customResourceNames:
  #Provide lowercase alphanumeric characters, '-' or '.'
  resourceNameLimit: 63
  masterPod:
    #when masterContainerName is not provided,<containerprefix>-es-master would be used.
    masterContainerName: ""
  dataPod:
    #when dataContainerName is not provided,<containerprefix>-es-data would be used.
    dataContainerName: ""
  clientPod:
    #when clientContainerName is not provided,<containerprefix>-es-client would be used.
    clientContainerName: ""
  #If job/container names are not provided, then default names would be generated by the chart in following format:
  #For job name: <podprefix>-<ReleaseName>-<string related to job>
  #For job containernames: <containerprefix>-<string related to job>
  postScaleInJob:
    name: ""
    postScaleInContainerName: ""
  preUpgradeSgMigrateJob:
    name: ""
    preUpgradeSgMigrateContainerName: ""
  postUpgradeSgMigrateJob:
    name: ""
    postUpgradeSgMigrateContainerName: ""
  preHealJob:
    name: ""
    preHealContainerName: ""
  postDeletePrehealJob:
    name: ""
    postDeletePrehealContainerName: ""
  postDeleteCleanupJob:
    name: ""
    postDeleteCleanupContainerName: ""
  postDeletePvcJob:
    name: ""
    postDeletePvcContainerName: ""

#This section allows to configure user defined name for pods and containers(For container this will take effect only when customResourceName is not provided for container)
# Options include:
# nameOverride: fullname would become ReleaseName + nameOverride
# fullnameOverride: fullname would become fullnameOverride
# If specified both, fullnameOverride would take the precedence.
nameOverride:
fullnameOverride:

es_securityContext:
  # Elasticsearch chart runs as elasticsearch user with UID: 1000
  # fsGroup is the gid that is assigned for the volumemounts mounted to the pod(fsGroup ID is used for block storage)
  fsGroup: 1000
  # The supplementalGroups ID applies to shared storage volumes. Uncomment below line to set supplemetary group.
  #supplementalGroups: [1000]
  # Uncomment below lines to configure SELinux label to a container.
  # For more details refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  #seLinuxOptions:
  #  level: "s0:c223,c111"

# Uncomment below lines to configure Elasticsearch pod specific annotations. Use 4 space indentation
#custom:
  #annotations: 


# Set to true when running in istio enabled namespace
istio:
  enabled: false
  # Health check port of istio envoy proxy
  envoy_health_chk_port: 15020
  #Istio version specified at chart level takes precedence over global level.
  #Accepts istio version in numeric X.Y format. Ex. 1.4/1.5
  version:

service:
  type: "ClusterIP"
  client_port: 9200
  client_nodeport: 30932
  master_port: 9300
  ## Start of custom modification of original chart, CSFS-31053
  master_nodeport: 30933
  ## End of custom modification of original chart
  name: "elasticsearch"

  prometheus_metrics:
    enabled: false
    #If searchguard is enabled, you will have to create a custom scrape job in cpro chart. Refer belk user-guide for the same.
    #Prometheus annotation for scraping metrics from elaticsearch https endpoints. If this annotation is modified, make sure to add the same name in custom scrape job created in cpro chart.
    pro_annotation_https_scrape: "prometheus.io/scrape_es"

#network_host is set to _site_ by default for IPv4 env. To know more about network_host and configure this parameter, please refer https://www.elastic.co/guide/en/elasticsearch/reference/7.0/modules-network.html#network-interface-values
## For IPv6 environment, this can be set to "_global:ipv6_". If the network interface is known, you can set it to "_[networkInterface]:ipv6_". For ex: "_eth0:ipv6_"
## When istio.enabled is true, network_host is fixed to "0.0.0.0"
network_host: "_site_"

#postscalein should be 0 to run postscalein job for cleaning up unused PVCs
postscalein: 0

#Delete policy of pre/post-upgrade jobs can be configured to modify the job retention
# For ex. if the jobs are to be retained even on success, remove hook-succeeded.
upgrade:
  hookDelPolicy: before-hook-creation, hook-succeeded

elasticsearch_master:
  name: master
  replicas: 3
  image: 
    #please update the below repo to elk_e if you wish to use elasticsearch centos8 based image. default is centos7 image.
    repo: elk_e_cos7
    tag: 7.8.0-20.09.03
  ImagePullPolicy: "IfNotPresent"
  resources:
    limits:
      cpu: "1"
      memory: "2Gi"
    requests:
      cpu: "500m"
      memory: "1Gi"
  es_java_opts: "-Xms1g -Xmx1g"
  antiAffinity: "soft"
  podAffinity: {}
  nodeAffinity: {}
  nodeSelector: {}
  tolerations: []
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

  #To configure cutomized labels to pods. Uncomment the below line and give labels after 4 space indentation
  #podLabels:
    #resourcetype: pod

esdata:
  name: data
  replicas: 2
  podweight: 100
  resources:
    limits:
      cpu: "1"
      memory: "4Gi"
    requests:
      cpu: "500m"
      memory: "2Gi"
  es_java_opts: "-Xms2g -Xmx2g"
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  antiAffinity: "soft"
  podAffinity: {}
  nodeAffinity: {}
  nodeSelector: {}
  tolerations: []
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

  #To configure cutomized labels to pods. Uncomment the below line and give labels after 4 space indentation
  #podLabels:
    #resourcetype: pod

elasticsearch_client:
  name: client
  replicas: 3
  resources:
    limits:
      cpu: "1"
      memory: "4Gi"
    requests:
      cpu: "500m"
      memory: "2Gi"
  es_java_opts: "-Xms2g -Xmx2g"
  antiAffinity: "soft"
  podAffinity: {}
  nodeAffinity: {}
  nodeSelector: {}
  tolerations: []
  #If SG is enabled you may have to increase the initialDelaySeconds depending on your cluster
  livenessProbe:
    initialDelaySeconds: 90
    periodSeconds: 20
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 90
    periodSeconds: 20
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3  

  #To configure cutomized labels to pods. Uncomment the below line and give labels after 4 space indentation
  #podLabels:
    #resourcetype: pod

persistence:
  #Supported storageClasses for BELK data are cinder, local-storage, hostpath.
  ## The value "" picks up the default storageClass configured in BCMT cluster.
  #If you want to use local storage as volume give "local-storage" in storageClassName.
  storageClassName: ""
  accessMode: ReadWriteOnce
  size: 25Gi
  # Size of persistent storage for master pod to persist cluster state
  masterStorage: 1Gi
  # set auto_delete to true if you want the persistent volume to also get deleted on deletion of the release.
  # This will delete all the previsous data stored in the persistent volume.
  # When local storage is used it will deleted only PVC not PV.
  auto_delete: false

backup_restore:
  ## The name of the storage class which the cluster should use for backup and restore. GlusterFS should use only when you need to take backup and restore the data
  storageClassName: glusterfs-storageclass
  ## The size of the PersistentVolume to allocate to each BELK es-data Pod in the StatefulSet
  ## For production servers this number should likely be much larger.
  #It should be more than 1.5times primary store size of ES.(Ex- 25*1.5=37.5)
  size: 40Gi
  

cbur:
  enabled: false
  #an integer. This value only applies to statefulset. The value can be 0,1 or 2.
  #Recommended value of brOption for BELK is 0.
  brOption: 0
  #the maximum copy you want to saved.
  maxCopy: 5
  #Modes supported now: "local","NETBKUP","AVAMAR","CEPHS3","AWSS3", case insensitive
  backendMode: "local"
  #It is used for scheduled backup task
  cronJob: "0 23 * * *"
  #Set below parameters to true for auto enabling cron job
  autoEnableCron: false
  #Set below parameter to true in case you want cronjob to be automatically deleted/updated based on autoEnableCron or cronJob parameters
  autoUpdateCron: false

  cbura:
    imageRepo: cbur/cbura
    imageTag: 1.0.3-1665
    imagePullPolicy: IfNotPresent
    userId: 1000
    resources:
      limits:
        cpu: "1"
        memory: "2Gi"
      requests:
        cpu: "500m"
        memory: "1Gi" 
    #tmp_size is the mounted volume size of /tmp directory for cbur-sidecar. 
    #The value should be around double the size of backup_restore.size
    tmp_size: 80Gi

kubectl:
  image:
    repo: tools/kubectl
    tag: v1.14.10-nano

jobResources:
  requests:
    cpu: 200m
    memory: 500Mi
  limits:
    cpu: 1
    memory: 1Gi


searchguard:
  image:
    #please update the below repo to elk_e_sg if you wish to use elasticsearch centos8 based image. default is centos7 image.
    repo: elk_e_sg_cos7
    tag: 7.8.0-20.09.04
  enable: false

  # When istio is enabled or http_ssl is disabled, admin user credentials must be provided in base64 encoding below
  adminUsername: ""
  adminPwd: ""

  # if authentication is required via keycloak, then set keycloak_auth to true
  # Provide base64 format of keycloak rootCA under base64_keycloak_rootca_pem when istio is not enabled
  keycloak_auth: false
  base64_keycloak_rootca_pem: <base64 format of keycloak rootCA pem>
  # when istio is enabled for belk and keycloak_auth is enabled, provide keycloak server details as explained below
  istio:
    # FQDN of ckey hostname that is externally accessible from browser
    extCkeyHostname: "ckey.io"    # Ex. extCkeyHostname: "ckey.io"
    # Location of ckey internal/external to the istio mesh. Default value is MESH_INTERNAL.
    extCkeyLocation: "MESH_INTERNAL"  # Accepted values: MESH_INTERNAL, MESH_EXTERNAL
    extCkeyIP: ""   # IP to be used for DNS resolution of ckey hostname from the cluster (required only when ckey is external to the mesh and ckey hostname is not resolvable from the cluster)

  # Create base64 encoding for keystore, keystorepasswd, truststore, truststorepasswd file and provide to below variables.
  # base64 encoding for passwords use below command
  # echo -n <string in double quotes> | base64
  # base64 encoding for files  use below command
  # base64 <filename>  | tr -d '\n'
  # When searchguard is enabled with istio, below configuration (from keystore_type to nodes_dn) is not required to be set as certificates are internally generated as part of docker entrypoint. 
  keystore_type: JKS
  truststore_type: JKS
  base64Keystore: <base64-keystore>
  base64KeystorePasswd: <base64-keypass>
  base64Truststore: <base64-truststore>
  base64TruststorePasswd: <base64-trustpass>
  base64ClientKeystore: <base64-clientkeystore>
  base64_client_cert: <base64-client-cert>
  base64_client_key: <base64-client-key>
  auth_admin_identity: <CN=admin,C=ELK>
  # Configure the DN of node certificate (keystore.jks) if the certificate does not contain an OID defined in its SAN.
  nodes_dn: ""

  #To disable SSL on REST layer for searchguard, configure http_ssl to false.
  # if istio.enabled is true, http_ssl is fixed internally to false and cannot be configured by user.
  http_ssl: true

  ## When SG is enabled, you can set the ciphers in the whitelist below. The ciphers provided in the list should be common in both JVM ciphers and kubelet ciphers.
  ## The details about JVM supported ciphers and kubelet ciphers are mentioned in BELK userguide. Please refer that before configuring the cipher list.
  ## Uncomment below line for setting cipher.
  #ciphers:
  #  - "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"
  #  - "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"

  sg_configmap:
    sg_internal_users_yml: |-
      ---
      _sg_meta:
        type: "internalusers"
        config_version: 2
      admin:
        reserved: true
        hidden: false
        hash: "$2a$12$VcCDgh2NDk07JGN0rjGbM.Ad41qVR/YFJcgHp0UGns5JDymv..TOG"
        backend_roles:
        - "admin"

    # refer https://docs.search-guard.com/latest/action-groups 
    sg_action_groups_yml: |-
      ---
      _sg_meta:
        type: "actiongroups"
        config_version: 2
    sg_config_yml: |-
      ---
      _sg_meta:
        type: "config"
        config_version: 2
      sg_config:
        dynamic:
          http:
            anonymous_auth_enabled: false
            xff:
              enabled: false
              internalProxies: ".+"
          authc:
            basic_internal_auth_domain:
              http_enabled: true
              transport_enabled: true
              order: 0
              http_authenticator:
                type: "basic"
                challenge: true   # Set this to false when keycloak authentication is enabled
                config: {}
              authentication_backend:
                type: "intern"
                config: {}
            keycloak_auth_domain:
              http_enabled: false              # Set to true to enable keycloak authentication
              transport_enabled: true
              order: 1
              http_authenticator:
                type: keycloak
                challenge: false
                config:
                  username_key: preferred_username
                  roles_key: <roles>
                  keycloak_connect_url: https://<keycloak_ip>:<port>/auth/realms/<realm_name>/.well-known/openid-configuration
                  client_id: <client_id>
                  client_secret: <client_secret>
                  ssl_validate: true            # Set to false when istio is enabled
              authentication_backend:
                  type: noop
            proxy_auth_domain:
              http_enabled: false
              transport_enabled: false
              order: 3
              http_authenticator:
                type: "proxy"
                challenge: false
                config:
                  user_header: "x-proxy-user"
                  #roles_header: "x-proxy-roles"
              authentication_backend:
                type: "noop"
                config: {}
            clientcert_auth_domain:
              http_enabled: false
              transport_enabled: false
              order: 2
              http_authenticator:
                type: "clientcert"
                config:
                  username_attribute: "cn"
                challenge: false
              authentication_backend:
                type: "noop"

    #refer https://docs.search-guard.com/latest/roles-permissions
    sg_roles_yml: |-
      ---
      _sg_meta:
        type: "roles"
        config_version: 2

    #refer https://docs.search-guard.com/latest/role-mapping-modes
    sg_roles_mapping_yml: |-
      ---
      _sg_meta:
        type: "rolesmapping"
        config_version: 2
      SGS_ALL_ACCESS:
        reserved: true
        hidden: false
        backend_roles:
        - "admin"
        description: "Migrated from v6"

      SGS_OWN_INDEX:
        reserved: false
        hidden: false
        users:
        - "*"
      SGS_KIBANA_USER:
        reserved: false
        backend_roles:
        - "kibanauser"
        description: "Maps kibanauser to SGS_KIBANA_USER"
      SGS_READALL:
        reserved: true
        backend_roles:
        - "readall"
      SGS_KIBANA_SERVER:
        reserved: true
        users:
        - "kibanaserver"

    ## Search Guard allows to block users by name (type: name), IP addresses (type: ip) and/or by a net mask (type: net_mask) configuration
    ## Blocks are either white-/ or black-listed, i.e. you can allow (verdict: allow) or disallow (verdict: disallow) client requests
    ## Precedence of blocking: White list -> Black list, i.e. white list is checked first and then black list for existing block configurations
    sg_blocks_yml: |-
      ---
      _sg_meta:
        type: "blocks"
        config_version: 2

      ## Demo user blocked
      #demo_user_blocked:
      #  type: "name"
      #  verdict: "disallow"
      #  value: ["Spock"] # you can also use regular expressions and wildcards for user name blocks, e.g. '* Spock'
      #  description: "Demo user blocked by name, a user with this name will be blocked"
      
      ## Demo IP blocked
      #demo_ip_blocked:
      #  type: "ip"
      #  verdict: "disallow"
      #  value: ["8.8.8.8"]
      #  description: "Demo IP blocked, i.e. this specific IP gets blocked"
      
      ## Demo net mask block
      #demo_net_mask_blocked:
      #  type: "net_mask"
      #  verdict: "allow"
      #  value: ["10.10.20.0/30"]
      #  description: "Demo net mask allowed, i.e. only client IPs which are part of this network are allowed"

    sg_tenants_yml: |-
      ---
      _sg_meta:
        type: "tenants"
        config_version: 2

